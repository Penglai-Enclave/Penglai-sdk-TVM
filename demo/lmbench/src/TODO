$Id$

Add standard deviation and other statistics calculations to "make stats"
in results

Add flags to various file-related benchmarks bw_file_rd, bw_mmap_rd,
lat_fcntl.c, lat_fs, lat_mmap, and lat_pagefault, for parallelism
which selects whether each instance has its own file or shares a
file.

Figure out how to improve lat_select.  It doesn't really work for
multi-processor systems.  Linus suggests that we have each process
do some amount of work, and vary the amount of work until context
switch times for the producer degrade.  The current architecture
of lat_select is too synchronous and favors simple hand-off
scheduling too much.  From Linus.

Look into threads vs. process scaling.  benchmp currently uses
separate processes (via fork()); some benchmarks such as page
faults and VM mapping might have very different performance
for threads vs. processes since Linux (at least) has per-memory
space locks for many of these things.  From Linus.

Rewrite scripts/lmbench to use the new "-P <parallelism>" model for
benchmarking parallel performance. 
[in progress]

Write/extend the results processing system/scripts to graph/display/
process results in the "-P <parallelism>" dimension, and to properly
handle results with differing parallelism when reporting standard
results.  The parallelism is stored in the results file as SYNC_MAX.

Add "-m <message size>" to networking benchmarks; this would specify
the number of bytes for each message's payload.  (message size must
be >= 1)
[partially complete]

Add "bw_udp" benchmark to measure UDP bandwidth
[in progress]

Make a bw_tcp mode that measures bandwidth for each block and graph that
as offset/bandwidth.

Make the disk stuff autosize such that you get the same number of data
points regardless of disk size.

Make sure that all memory referencing benchmarks reference all the
memory.  So no partial references in the BENCH() macro, it has
to call something that touches all of it.

Make all benchmarks use the timing overhead for the loop and all call
use_result.  So all are in function calls.

Fix the getsummary to include simple calls.

Think about the issues of int/long/long long/double/long double
load/stores.  Maybe do them all.  This will (at least) require
adding a test to scripts/build for the presence of long double
on this system.

Make all results print out bandwidths in powers of 10/sizes in powers of two.

Make the lat_mem_rd walk in different strides.  Try and make it so that
you flip back and forth between the same cache line.  So if you assume
4 byte pointers and 8 byte cache lines, you do

	[ x _ ] [ _ x ] [ x _ ] [ _ x]

such that the stride switches between 4 & 12 bytes.  Make sure this screws
up HP's prefetch.

Documentation on porting.

Check that file size is right in the benchmarking system.

Compiler version info included in results.  XXX - do this!

Assembler output for the files that need it.

memory store latency (complex)
	Why can't I just use the read one and make it write?
	Well, because the read one is list oriented and I need to figure
	out reasonable math for the write case.  The read one is a load
	per statement whereas the write one will be more work, I think.

RPC numbers reserved for the benchmark.

Check all the error outputs and make sure they are consistent.

On all the normalized graphs, make sure that they mean the same thing.
I do not think that the bandwidth measurements are "correct" in this
sense.

Move the k/m postfix routine into timing.c and make it an interface.

Document the timing.c interfaces.

Run the whole suite through gcc -Wall and fix all the errors.  Also make
sure that it compiles and has the right sizes for 64 bit OS.

[Mon Jul  1 13:30:01 PDT 1996, after meeting w/ Kevin]

Do the load latency like so

	loop:
		load	r1
		{
		increase the number of nops until they start to make the
		run time longer - the last one was the memory latency.
		}
		use the register
		{
		increase the number of nops until they start to make the
		run time longer - the last one was the cache fill shadow.
		}
		repeat

Do the same thing w/ a varying number of loads (& their uses), showing 
the number of outstanding loads implemented to L1, L2, mem.

Do hand made assembler to get accurate numbers.  Provide C source that 
mimics the hand made assembler for new machines.

Think about a report format for the hardware stuff that showed the
numbers as triples L1/L2/mem (or quadruples for alphas).

